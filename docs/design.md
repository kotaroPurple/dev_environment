# 設計方針

## デザインゴール
- オンライン時系列処理をシンプルに構築できる拡張性の高いフレームワークを提供する
- 組み込み環境でも成立する単一スレッドの逐次ブロック処理を実現する
- PyTorch の `Dataset`/`DataLoader` に親和性のあるデータ供給 API を整備し、学習コストを低減する
- データ構造と処理ノードの型安全性を高め、再利用性を最大化する
- パイプライン構築を宣言的に記述できる API を提供し、開発者の負担を軽減する

## 全体アーキテクチャ
- `DatasetLayer`: PyTorch 互換の `StreamDataset` を定義し、ブロックアクセスを抽象化する
- `LoaderLayer`: `StreamDataLoader` がデータセットからブロックを取り出し、逐次・同期的にパイプラインへ供給する
- `ProcessingLayer`: 抽象基底クラスを用意し、個別処理ノードを実装
- `PipelineOrchestrator`: 処理順序の解決、依存関係管理、実行制御
- `IOAdapters`: 外部データソースやシンクへの接続を担うアダプタ群
- `Monitoring`: ロギング、メトリクス収集、デバッグ支援

## データモデル設計
- `BaseTimeSeries`: サンプリング周波数、タイムスタンプ、メタ情報を保持
- `StreamDataset`: `__len__`, `__getitem__`, `stream()` を備え、連続ブロックアクセスやシーケンシャルリセットを扱う
- `StreamDataLoader`: ブロックサイズと停止条件を管理し、逐次的にブロックを取得してパイプラインへ渡す
- `BlockBuffer`: push 操作でブロックデータを蓄積し、後段処理へ参照を提供
- `collate_block`: DataLoader の `collate_fn` に相当し、データコンテナへ変換するユーティリティ (組み込み向けにコピー/変換コストを最小化)
- 型アノテーションを活用し、静的解析で整合性を確認できるようにする
- 多次元データは `numpy.ndarray` 等を内部表現とし、抽象インターフェースで隠蔽

## 処理ノード設計
- `ProcessingNode` 抽象クラスで `requires()`, `produces()`, `process()` を定義
- 依存データは `requires()` が返すデータコンテナ型リストで宣言する
- `process()` はデータローダから供給された入力ブロックを受け取り新たなデータコンテナまたは副作用を生成する
- 複数出力を持つ場合は命名済みスロットを返却し、後続ノードが参照できるようにする
- ノードは必要に応じて `collate_block` を差し替え、特定フォーマットのデータを効率的に処理できる
- 各ノードは処理完了時に同期的に制御を戻し、次のブロック取得が安全に開始できるようにする

## パイプライン制御
- `PipelineBuilder` が処理ノードと依存、利用するストリームデータセット/データローダを登録し、有向非巡回グラフとして構築
- 実行時はトポロジカルソートで順序を決定し、データローダから受け取るブロックを 1 つずつ順番に処理する
- オーケストレータはブロック処理の終了を待ってから次のブロック取得を指示し、時間制約内での連続処理を保証する
- 途中結果のキャッシュ戦略を選択できる (メモリ保持、オンデマンド再計算)

## 入出力アダプタ
- `DataSourceAdapter` が外部システムからデータブロックを読込む
- `StreamDataset` は `DataSourceAdapter` を利用し、オンライン/オフラインの切替や再開位置の管理を実装する
- `DataSinkAdapter` が処理結果をログ、ファイル、メッセージキュー等へ送出
- 抽象クラスで基本契約を定義し、プロジェクトごとの実装を追加可能とする
- 組み込み向けに、データ取得・送出はいずれも同期 I/O を前提としたシンプルな API とする

## エラー処理と監視
- 各ノードは例外を補足して `PipelineOrchestrator` に通知する
- データローダは読み出し例外を即時に返し、再試行・スキップ・停止の戦略をオーケストレータが決定する
- ポリシー (停止/継続/スキップ) を設定可能にし、運用要件に応じて制御
- ログレベルとメトリクス (処理時間、バッファサイズ) を標準化する

## 設定管理
- パイプライン定義はコードベースを基本とし、YAML 等の設定ファイルへの対応を検討
- データセット/データローダのパラメータ (ブロックサイズ、停止条件、再開位置) を設定で切り替えられるようにする
- 設定値は `pydantic` や dataclass によるバリデーション層を挟む

## テスト戦略
- ユニットテスト: データコンテナ、データセット/データローダ、ノード、オーケストレータの単体検証
- 結合テスト: シンプルなパイプライン構成でブロック処理の流れを確認
- パフォーマンステスト: ブロックサイズや処理時間を計測し、単一スレッドでリアルタイム制約を満たすことを評価

## 将来拡張
- GPU や分散処理ノードへの対応を検討
- PyTorch `DataLoader` との相互運用を強化し、学習タスクとの連携を容易にする
- 必要に応じて並列処理オプションを追加できる余地を残す (現行は逐次実行)
- 処理グラフの可視化ツールと Web UI の整備
- オンライン学習アルゴリズムやアラート機構のプラグイン化
